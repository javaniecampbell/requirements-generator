# Implementing V2 - Simple Agent Approach

## Overview

Based on V1 implmentation I took a naive approach in getting general flow done to follow the 4 step process in in getting a general document.

The PoC of v1 had few limitations as follows:

1. The LLM model was not opitmized for the task and produced generic responses.

2. There was no concept of state management and context between user queries.

3. The model could not take follow up questions or build on previous responses.

4. The model often generated incomplete responses when trying to build long documents i.e. the `finish_reason == "length"` was not handled properly.

5. The `finish_reason == "stop"` was not handled to ensure a loop was added to keep the conversation going.

6. The message history was not captured to be used in upcoming conversation calls for context

7. The message history when streaming chunks was not captured.

## Approach for V2

To address the above limitations, I took a simple agent approach as follows:

1. Create an `Agent` class to manage the conversation state and context. The class will have properties to store:

- message_history (list): To store previous messages
- context (dict): To store any additional context needed
- constructor initializes empty context and message history
- add_message(message) method to append messages to history
- get_context() method to return copy of context
- set_context(new_context) method to update context
- response(query) method to generate response using query, context and history
The response method would:
- Check for finish reasons and handle appropriately
- Extract query entities, intents, keywords etc using NLP
- Lookup existing responses in message history and context before generating new ones
- Generate initial response using LLM model
- Update context and history as new information is gathered
- Check context and history to continue discussion and build on previous responses
- Handle finish reasons to continue conversation flow appropriately

```python
class Agent:
    def __init__(self):
        self.message_history = []
        self.context = {}
    def add_message(self, message):
        self.message_history.append(message)
    def get_context(self):
        return self.context.copy()
    def set_context(self, new_context):
        self.context = new_context
    def response(self, query):
        # Check for finish reasons
        if finish_reason == "length":
            # Handle length limit
            return "I have reached the character limit for this response. What else can I help explain?"
        # Generate initial response
        response = generate_response(query, self.context, self.message_history)
        # Update context and history
        
    def generate_response(self, query, context, history):
        response = self.model.generate(query, context=context, history=history)
        # Check response for finish reasons or follow ups
        # Update context with any new info extracted from response or query



```

2. Use a context object to store state between conversation turns

3. 
